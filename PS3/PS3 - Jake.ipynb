{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6e674e",
   "metadata": {},
   "source": [
    "## 1. How many Spam Emails are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "568c63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spam(path = \"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\", folders = ['enron1','enron2']):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    #path = Path(\"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\")\n",
    "    path = Path(path)\n",
    "    spam_count = 0\n",
    "    for folder in folders:\n",
    "        file_names = os.listdir(path / folder / 'spam')\n",
    "        for file_name in file_names:\n",
    "            if 'spam' in file_name:\n",
    "                spam_count += 1\n",
    "    print('There are', spam_count, 'spam emails in', folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8210f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2993 spam emails in ['enron1', 'enron2']\n"
     ]
    }
   ],
   "source": [
    "count_spam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaac7f",
   "metadata": {},
   "source": [
    "## 2. Structure the email data from the 2 directories into 1 dataframe with columns: Status, Subject, Body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e5c65",
   "metadata": {},
   "source": [
    "#### Specify the folders that will be included and the path leading to the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b233e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['enron1','enron2']\n",
    "status = ['spam','ham']\n",
    "path1 = \"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\{folder}\\\\{status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d70fc",
   "metadata": {},
   "source": [
    "#### Create the paths containing all the desired emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5234fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enron1', 'spam'), ('enron1', 'ham'), ('enron2', 'spam'), ('enron2', 'ham')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "directories = list(product(folders, status))\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabc7d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\ham']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for i in directories:\n",
    "    paths.append(path1.format(folder=i[0],status=i[1]))\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce068ee",
   "metadata": {},
   "source": [
    "#### List all the files in each `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17bad3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_paths = [glob.glob(pathname=path + '\\\\*') for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478901c0",
   "metadata": {},
   "source": [
    "#### Now we have all the file paths of the emails in the specified folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01f4d8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0006.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0008.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0017.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0018.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0026.2003-12-18.GP.spam.txt']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf0aa27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0001.1999-12-10.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0002.1999-12-13.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0003.1999-12-14.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0004.1999-12-14.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0005.1999-12-14.farmer.ham.txt']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[1][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2590ad5",
   "metadata": {},
   "source": [
    "#### Having acquired the file paths, we can now extract the status, subject and message body of the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6ec9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status has 11026 elements.\n",
      "Subject has 11026 elements.\n",
      "Body has 11026 elements.\n"
     ]
    }
   ],
   "source": [
    "subjects = []\n",
    "bodies = []\n",
    "status = []\n",
    "\n",
    "# for each path\n",
    "for file_path in file_paths:\n",
    "    # for each file in path\n",
    "    for i in file_path:\n",
    "        # for status\n",
    "        if 'spam.txt' in i:\n",
    "            status.append('spam')\n",
    "        elif 'ham.txt' in i:\n",
    "            status.append('ham')\n",
    "        # extract the subject from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            subject = f.readlines()[0]\n",
    "            subject = subject[9:]\n",
    "            subjects.append(subject)\n",
    "        # extract body message from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            body = f.readlines()\n",
    "            body = body[1:]\n",
    "            bodies.append(body)\n",
    "            \n",
    "# join each sub-elements of the bodies list\n",
    "bodies = [' '.join(i) for i in bodies]\n",
    "\n",
    "print('Status has', len(status), 'elements.')\n",
    "print('Subject has', len(subjects), 'elements.')\n",
    "print('Body has', len(bodies), 'elements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f0c4c",
   "metadata": {},
   "source": [
    "#### Now, use the lists to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "351fdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6068cc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>spam</td>\n",
       "      <td>collene medg stockplay of the day jeer\\n</td>\n",
       "      <td>watson ,\\n medg - our best pick with rapid gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : vmi agreements\\n</td>\n",
       "      <td>ravi ,\\n maybe stinson can get on this confere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>ham</td>\n",
       "      <td>enron methanol ; meter # : 988291\\n</td>\n",
       "      <td>this is a follow up to the note i gave you on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : new eol product\\n</td>\n",
       "      <td>the texas gas group will definitely be rolling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : risk 2000 - boston\\n</td>\n",
       "      <td>oliver ,\\n i apologize for the delay . i was t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>ham</td>\n",
       "      <td>message 4\\n</td>\n",
       "      <td>dear dr . kaminski ,\\n this is a message of di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10921</th>\n",
       "      <td>ham</td>\n",
       "      <td>your advice is appreciated\\n</td>\n",
       "      <td>vince ,\\n in the morning we were talking about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>spam</td>\n",
       "      <td>best free adult dating\\n</td>\n",
       "      <td>search for sexual partners in your areaclick h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>ham</td>\n",
       "      <td>cross training\\n</td>\n",
       "      <td>in an attempt to continue cross training on ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>ham</td>\n",
       "      <td>per nelson ferries ( dealmaker ) : we do pay s...</td>\n",
       "      <td>please change the base purchase deals to refle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Status                                            Subject  \\\n",
       "970     spam           collene medg stockplay of the day jeer\\n   \n",
       "7059     ham                              re : vmi agreements\\n   \n",
       "2104     ham                enron methanol ; meter # : 988291\\n   \n",
       "2553     ham                             re : new eol product\\n   \n",
       "6885     ham                          re : risk 2000 - boston\\n   \n",
       "8148     ham                                        message 4\\n   \n",
       "10921    ham                       your advice is appreciated\\n   \n",
       "1450    spam                           best free adult dating\\n   \n",
       "1867     ham                                   cross training\\n   \n",
       "1842     ham  per nelson ferries ( dealmaker ) : we do pay s...   \n",
       "\n",
       "                                                    Body  \n",
       "970    watson ,\\n medg - our best pick with rapid gro...  \n",
       "7059   ravi ,\\n maybe stinson can get on this confere...  \n",
       "2104   this is a follow up to the note i gave you on ...  \n",
       "2553   the texas gas group will definitely be rolling...  \n",
       "6885   oliver ,\\n i apologize for the delay . i was t...  \n",
       "8148   dear dr . kaminski ,\\n this is a message of di...  \n",
       "10921  vince ,\\n in the morning we were talking about...  \n",
       "1450   search for sexual partners in your areaclick h...  \n",
       "1867   in an attempt to continue cross training on ou...  \n",
       "1842   please change the base purchase deals to refle...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.DataFrame(list(zip(status,subjects,bodies)), columns=['Status','Subject','Body'])\n",
    "enron.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b51646",
   "metadata": {},
   "source": [
    "## 3. Build a Naive Bayes classifier to classify whether emails are spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b990c",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37ab5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "231da67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>ham</td>\n",
       "      <td>rdi conference - may 17 - 19 , 2000\\n</td>\n",
       "      <td>hi ,\\n i ' d like to make a personal invitatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>spam</td>\n",
       "      <td>complete online pharmacy with same day shipping\\n</td>\n",
       "      <td>meridia ® is an fda - approved oral prescripti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>spam</td>\n",
       "      <td>looking for a specific medication ? let us kno...</td>\n",
       "      <td>healthy living for everyday life .\\n we rarely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : hello from london\\n</td>\n",
       "      <td>zimin ,\\n i have a copy of the article .\\n i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>ham</td>\n",
       "      <td>oasis on - line\\n</td>\n",
       "      <td>daren - - -\\n oasis will be doing away with th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Status                                            Subject  \\\n",
       "7442    ham              rdi conference - may 17 - 19 , 2000\\n   \n",
       "5209   spam  complete online pharmacy with same day shipping\\n   \n",
       "5924   spam  looking for a specific medication ? let us kno...   \n",
       "7686    ham                           re : hello from london\\n   \n",
       "4417    ham                                  oasis on - line\\n   \n",
       "\n",
       "                                                   Body  \n",
       "7442  hi ,\\n i ' d like to make a personal invitatio...  \n",
       "5209  meridia ® is an fda - approved oral prescripti...  \n",
       "5924  healthy living for everyday life .\\n we rarely...  \n",
       "7686  zimin ,\\n i have a copy of the article .\\n i a...  \n",
       "4417  daren - - -\\n oasis will be doing away with th...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23b4d3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11026, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0a067",
   "metadata": {},
   "source": [
    "#### Create `Spam` column from the `Status` column and delete `Status` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8059da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron['Spam'] = [1 if i == 'spam' else 0 for i in enron['Status']]\n",
    "enron.drop('Status', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ffbfa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>re : ami chokshi resigns\\n</td>\n",
       "      <td>i have an exit interview scheduled for 2 pm on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9349</th>\n",
       "      <td>chonawee supatgiat / corp / enron is out of th...</td>\n",
       "      <td>i will be out of the office from 11 / 27 / 200...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>new love tabs shop .\\n</td>\n",
       "      <td>visit our llcensed online dragstore for the be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7230</th>\n",
       "      <td>enron media / advertising\\n</td>\n",
       "      <td>simon ,\\n please forward a copy of my ken rice...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>re : \" expected tail loss \" for equity portfol...</td>\n",
       "      <td>everybody ,\\n i attached here the equity portf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject  \\\n",
       "3355                          re : ami chokshi resigns\\n   \n",
       "9349   chonawee supatgiat / corp / enron is out of th...   \n",
       "6225                              new love tabs shop .\\n   \n",
       "7230                         enron media / advertising\\n   \n",
       "10146  re : \" expected tail loss \" for equity portfol...   \n",
       "\n",
       "                                                    Body  Spam  \n",
       "3355   i have an exit interview scheduled for 2 pm on...     0  \n",
       "9349   i will be out of the office from 11 / 27 / 200...     0  \n",
       "6225   visit our llcensed online dragstore for the be...     1  \n",
       "7230   simon ,\\n please forward a copy of my ken rice...     0  \n",
       "10146  everybody ,\\n i attached here the equity portf...     0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb53f4",
   "metadata": {},
   "source": [
    "#### Split data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63ecb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bf1f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(enron[\"Body\"], enron[\"Spam\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6172f4",
   "metadata": {},
   "source": [
    "#### Import libraries for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88e0ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92209936",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_X = vectorizer.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b43fb",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "391b1515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(tfidf_train_X.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60b3c7",
   "metadata": {},
   "source": [
    "## 4. What is the longest ham email?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df0328",
   "metadata": {},
   "source": [
    "#### Create a dataframe containing all ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de8d3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hams = enron[enron['Spam'] == 0][['Body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21540d2a",
   "metadata": {},
   "source": [
    "#### Create a column containing the lengths of each emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cbdf9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hams['Lengths'] = [len(i) for i in hams['Body']]\n",
    "hams.drop('Body',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37904c18",
   "metadata": {},
   "source": [
    "#### Get the index of the longest ham email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3dfa28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths    10765\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "longest_ham = hams.idxmax()\n",
    "print(longest_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f096aa1",
   "metadata": {},
   "source": [
    "#### Print the longest ham email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "339feca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10765    fyi news articles from indian press .\\n - - - ...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.iloc[longest_ham,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b2a50",
   "metadata": {},
   "source": [
    "#### The longest ham email has `43888` characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "526c174a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lengths    43888\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hams.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e332b92",
   "metadata": {},
   "source": [
    "## 5. What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fb0bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acbf11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3308, 58021)\n",
      "Accuracy: 94.01 percent\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_X = vectorizer.transform(test_X)\n",
    "print(tfidf_test_X.shape)\n",
    "scores = cross_val_score(classifier, tfidf_test_X.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58edb51",
   "metadata": {},
   "source": [
    "**The model has an accuracy of `94.01%`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118b393",
   "metadata": {},
   "source": [
    "## 6. Include the Subject in the analysis of the emails, does the accuracy/performance of the model increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34166c1e",
   "metadata": {},
   "source": [
    "#### Create a new column containing the concatenation of `Subject` and `Body`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9331b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron['Total'] = [sub + bod for (sub, bod) in zip(enron.iloc[:,0],enron.iloc[:,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a83f9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Spam</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dobmeos with hgh my energy level has gone up !...</td>\n",
       "      <td>introducing\\n doctor - formulated\\n hgh\\n huma...</td>\n",
       "      <td>1</td>\n",
       "      <td>dobmeos with hgh my energy level has gone up !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your prescription is ready . . oxwq s f e\\n</td>\n",
       "      <td>low cost prescription medications\\n soma , ult...</td>\n",
       "      <td>1</td>\n",
       "      <td>your prescription is ready . . oxwq s f e\\nlow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get that new car 8434\\n</td>\n",
       "      <td>people nowthe weather or climate in any partic...</td>\n",
       "      <td>1</td>\n",
       "      <td>get that new car 8434\\npeople nowthe weather o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>await your response\\n</td>\n",
       "      <td>dear partner ,\\n we are a team of government o...</td>\n",
       "      <td>1</td>\n",
       "      <td>await your response\\ndear partner ,\\n we are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coca cola , mbna america , nascar partner with...</td>\n",
       "      <td>stock\\n profile\\n about\\n company\\n investment...</td>\n",
       "      <td>1</td>\n",
       "      <td>coca cola , mbna america , nascar partner with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  dobmeos with hgh my energy level has gone up !...   \n",
       "1        your prescription is ready . . oxwq s f e\\n   \n",
       "2                            get that new car 8434\\n   \n",
       "3                              await your response\\n   \n",
       "4  coca cola , mbna america , nascar partner with...   \n",
       "\n",
       "                                                Body  Spam  \\\n",
       "0  introducing\\n doctor - formulated\\n hgh\\n huma...     1   \n",
       "1  low cost prescription medications\\n soma , ult...     1   \n",
       "2  people nowthe weather or climate in any partic...     1   \n",
       "3  dear partner ,\\n we are a team of government o...     1   \n",
       "4  stock\\n profile\\n about\\n company\\n investment...     1   \n",
       "\n",
       "                                               Total  \n",
       "0  dobmeos with hgh my energy level has gone up !...  \n",
       "1  your prescription is ready . . oxwq s f e\\nlow...  \n",
       "2  get that new car 8434\\npeople nowthe weather o...  \n",
       "3  await your response\\ndear partner ,\\n we are a...  \n",
       "4  coca cola , mbna america , nascar partner with...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "354f4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(enron[\"Total\"], enron[\"Spam\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65bba0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_X = vectorizer.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df92e967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(tfidf_train_X.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4d9a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3308, 58864)\n",
      "Accuracy: 94.68 percent\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_X = vectorizer.transform(test_X)\n",
    "print(tfidf_test_X.shape)\n",
    "scores = cross_val_score(classifier, tfidf_test_X.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864926c7",
   "metadata": {},
   "source": [
    "**The accuracy improved by `0.67%`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e75000",
   "metadata": {},
   "source": [
    "## Bonus : Answer questions 1-6 using Enron 1,2, and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1b402",
   "metadata": {},
   "source": [
    "**Answer to bonus question is in the jupyter notebook `PS3 - Bonus - Jake.ipynb`.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
