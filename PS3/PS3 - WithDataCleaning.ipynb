{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6e674e",
   "metadata": {},
   "source": [
    "## 1. How many Spam Emails are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "568c63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spam(path = \"C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\", folders = ['enron1','enron2']):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    path = Path(path)\n",
    "    spam_count = 0\n",
    "    for folder in folders:\n",
    "        file_names = os.listdir(path / folder / 'spam')\n",
    "        for file_name in file_names:\n",
    "            if 'spam' in file_name:\n",
    "                spam_count += 1\n",
    "    print('There are', spam_count, 'spam emails in', folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8210f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2993 spam emails in ['enron1', 'enron2']\n"
     ]
    }
   ],
   "source": [
    "count_spam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaac7f",
   "metadata": {},
   "source": [
    "## 2. Structure the email data from the 2 directories into 1 dataframe with columns: Status, Subject, Body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e5c65",
   "metadata": {},
   "source": [
    "#### Specify the folders that will be included and the path leading to the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2b233e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['enron1','enron2']\n",
    "status = ['spam','ham']\n",
    "path1 = \"C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\{folder}\\\\{status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d70fc",
   "metadata": {},
   "source": [
    "#### Create the paths containing all the desired emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e5234fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enron1', 'spam'), ('enron1', 'ham'), ('enron2', 'spam'), ('enron2', 'ham')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "directories = list(product(folders, status))\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fabc7d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\spam',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\ham']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for i in directories:\n",
    "    paths.append(path1.format(folder=i[0],status=i[1]))\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce068ee",
   "metadata": {},
   "source": [
    "#### List all the files in each `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "17bad3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_paths = [glob.glob(pathname=path + '\\\\*') for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478901c0",
   "metadata": {},
   "source": [
    "#### Now we have all the file paths of the emails in the specified folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "01f4d8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0006.2003-12-18.GP.spam.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0008.2003-12-18.GP.spam.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0017.2003-12-18.GP.spam.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0018.2003-12-18.GP.spam.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0026.2003-12-18.GP.spam.txt']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cf0aa27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0001.1999-12-10.farmer.ham.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0002.1999-12-13.farmer.ham.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0003.1999-12-14.farmer.ham.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0004.1999-12-14.farmer.ham.txt',\n",
       " 'C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0005.1999-12-14.farmer.ham.txt']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[1][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2590ad5",
   "metadata": {},
   "source": [
    "#### Having acquired the file paths, we can now extract the status, subject and message body of the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e6ec9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status has 11026 elements.\n",
      "Subject has 11026 elements.\n",
      "Body has 11026 elements.\n"
     ]
    }
   ],
   "source": [
    "subjects = []\n",
    "bodies = []\n",
    "status = []\n",
    "\n",
    "# for each path\n",
    "for file_path in file_paths:\n",
    "    # for each file in path\n",
    "    for i in file_path:\n",
    "        # for status\n",
    "        if 'spam.txt' in i:\n",
    "            status.append('spam')\n",
    "        elif 'ham.txt' in i:\n",
    "            status.append('ham')\n",
    "        # extract the subject from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            subject = f.readlines()[0]\n",
    "            subject = subject[9:]\n",
    "            subjects.append(subject)\n",
    "        # extract body message from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            body = f.readlines()\n",
    "            body = body[1:]\n",
    "            bodies.append(body)\n",
    "            \n",
    "# join each sub-elements of the bodies list\n",
    "bodies = [' '.join(i) for i in bodies]\n",
    "\n",
    "print('Status has', len(status), 'elements.')\n",
    "print('Subject has', len(subjects), 'elements.')\n",
    "print('Body has', len(bodies), 'elements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9549de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = [1 if i == 'spam' else 0 for i in status]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f0c4c",
   "metadata": {},
   "source": [
    "#### Now, use the lists to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "351fdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6068cc2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dobmeos with hgh my energy level has gone up !...</td>\n",
       "      <td>introducing\\n doctor - formulated\\n hgh\\n huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>your prescription is ready . . oxwq s f e\\n</td>\n",
       "      <td>low cost prescription medications\\n soma , ult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>get that new car 8434\\n</td>\n",
       "      <td>people nowthe weather or climate in any partic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>await your response\\n</td>\n",
       "      <td>dear partner ,\\n we are a team of government o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>coca cola , mbna america , nascar partner with...</td>\n",
       "      <td>stock\\n profile\\n about\\n company\\n investment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>emerging small cap\\n</td>\n",
       "      <td>to exit all additional mailings - - - &gt;\\n [ pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>re : patchs work better then pillz\\n</td>\n",
       "      <td>worlds first dermal p ; atch technology for p ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>paliourg udtih 7 wcwknoanopkt\\n</td>\n",
       "      <td>good morning paliourg !\\n last miraculous and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>real products for real people . b\\n</td>\n",
       "      <td>dont waste your time at the doctors office !\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>^ . pe , nis s ^ ize mat ; ters ! yhvqbvdboevk...</td>\n",
       "      <td>briababhdpr frdjvdbesk cdpizacqjkufx hfkosxcym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Spam                                            Subject  \\\n",
       "0     1  dobmeos with hgh my energy level has gone up !...   \n",
       "1     1        your prescription is ready . . oxwq s f e\\n   \n",
       "2     1                            get that new car 8434\\n   \n",
       "3     1                              await your response\\n   \n",
       "4     1  coca cola , mbna america , nascar partner with...   \n",
       "5     1                               emerging small cap\\n   \n",
       "6     1               re : patchs work better then pillz\\n   \n",
       "7     1                    paliourg udtih 7 wcwknoanopkt\\n   \n",
       "8     1                real products for real people . b\\n   \n",
       "9     1  ^ . pe , nis s ^ ize mat ; ters ! yhvqbvdboevk...   \n",
       "\n",
       "                                                Body  \n",
       "0  introducing\\n doctor - formulated\\n hgh\\n huma...  \n",
       "1  low cost prescription medications\\n soma , ult...  \n",
       "2  people nowthe weather or climate in any partic...  \n",
       "3  dear partner ,\\n we are a team of government o...  \n",
       "4  stock\\n profile\\n about\\n company\\n investment...  \n",
       "5  to exit all additional mailings - - - >\\n [ pr...  \n",
       "6  worlds first dermal p ; atch technology for p ...  \n",
       "7  good morning paliourg !\\n last miraculous and ...  \n",
       "8  dont waste your time at the doctors office !\\n...  \n",
       "9  briababhdpr frdjvdbesk cdpizacqjkufx hfkosxcym...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.DataFrame(list(zip(spam,subjects,bodies)), columns=['Spam','Subject','Body'])\n",
    "enron.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ae7a5",
   "metadata": {},
   "source": [
    "#### Save the dataframe as a `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "54f5bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron.to_csv(path_or_buf=\"C:\\\\Users\\\\jakeedison.bersabe\\\\Cadetship\\\\EDA\\\\EDA-Projects\\\\PS3\\\\heron.csv\", index=False, line_terminator='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "869e72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heron = pd.read_csv('heron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dd345e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spam\n",
       "0       8033\n",
       "1       2993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heron[['Spam']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c84ba7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11026, 3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heron.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f69bf1",
   "metadata": {},
   "source": [
    "#### Import libraries for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8858243f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jakeedison.bersabe\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c18c0c",
   "metadata": {},
   "source": [
    "#### Create the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "42a9c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() # extracts the root word of a word\n",
    "all_stopwords = stopwords.words('english') # list of english stop words\n",
    "all_stopwords.remove('not') # remove not from the stop words\n",
    "corpus = []\n",
    "for i in range(0, heron.shape[0]):\n",
    "    body = re.sub(r'[^a-zA-Z]', ' ', str(heron['Body'][i])) # remove punctuations, replacing it with whitespace\n",
    "    body = body.lower() # lower case everything\n",
    "    body = body.split() \n",
    "    body = [ps.stem(word) for word in body if not word in set(all_stopwords)] # remove stopwords and extract root word\n",
    "    body = ' '.join(body)\n",
    "    corpus.append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "146d8026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'introduc doctor formul hgh human growth hormon also call hgh refer medic scienc master hormon plenti young near age twenti one bodi begin produc less time forti nearli everyon defici hgh eighti product normal diminish least advantag hgh increas muscl strength loss bodi fat increas bone densiti lower blood pressur quicken wound heal reduc cellulit improv vision wrinkl disappear increas skin thick textur increas energi level improv sleep emot stabil improv memori mental alert increas sexual potenc resist common ill strengthen heart muscl control cholesterol control mood swing new hair growth color restor read websit unsubscrib'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89def75c",
   "metadata": {},
   "source": [
    "## Using `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b790e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tfid_vec = TfidfVectorizer(max_features=15000)\n",
    "X = tfid_vec.fit_transform(corpus).toarray()\n",
    "y = heron.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "855aa647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11026, 15000)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f1e45b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "296a9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "613ce1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4e1b79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b2b70521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1558   57]\n",
      " [  32  559]]\n",
      "Accuracy: 0.9596554850407978\n",
      "Recall score: 0.9458544839255499\n",
      "Precision score: 0.9074675324675324\n",
      "F1 score: 0.9262634631317315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall score:\", recall_score(y_test, y_pred))\n",
    "print(\"Precision score:\", precision_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccbe2c",
   "metadata": {},
   "source": [
    "## Using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b56d4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=22000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = heron.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1e875dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a5536285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_count = GaussianNB()\n",
    "classifier_count.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ab5114d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_count.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ed0c4a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1594   21]\n",
      " [  99  492]]\n",
      "Accuracy: 0.9456029011786038\n",
      "Recall score: 0.8324873096446701\n",
      "Precision score: 0.9590643274853801\n",
      "F1 score: 0.8913043478260869\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall score:\", recall_score(y_test, y_pred))\n",
    "print(\"Precision score:\", precision_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
