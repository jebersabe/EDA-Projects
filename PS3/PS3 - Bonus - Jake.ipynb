{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f771ad57",
   "metadata": {},
   "source": [
    "# PS3 Bonus Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e674e",
   "metadata": {},
   "source": [
    "## 1. How many Spam Emails are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568c63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spam(path = \"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\", folders = ['enron1','enron2','enron3']):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    #path = Path(\"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\")\n",
    "    path = Path(path)\n",
    "    spam_count = 0\n",
    "    for folder in folders:\n",
    "        file_names = os.listdir(path / folder / 'spam')\n",
    "        for file_name in file_names:\n",
    "            if 'spam.txt' in file_name:\n",
    "                spam_count += 1\n",
    "    print('There are', spam_count, 'spam emails in', folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8210f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4492 spam emails in ['enron1', 'enron2', 'enron3']\n"
     ]
    }
   ],
   "source": [
    "count_spam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaac7f",
   "metadata": {},
   "source": [
    "## 2. Structure the email data from the 2 directories into 1 dataframe with columns: Status, Subject, Body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e5c65",
   "metadata": {},
   "source": [
    "#### Specify the folders that will be included and the path leading to the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b233e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['enron1','enron2','enron3']\n",
    "status = ['spam','ham']\n",
    "path1 = \"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\{folder}\\\\{status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d70fc",
   "metadata": {},
   "source": [
    "#### Create the paths containing all the desired emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5234fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enron1', 'spam'),\n",
       " ('enron1', 'ham'),\n",
       " ('enron2', 'spam'),\n",
       " ('enron2', 'ham'),\n",
       " ('enron3', 'spam'),\n",
       " ('enron3', 'ham')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "directories = list(product(folders, status))\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabc7d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\ham',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron3\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron3\\\\ham']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for i in directories:\n",
    "    paths.append(path1.format(folder=i[0],status=i[1]))\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce068ee",
   "metadata": {},
   "source": [
    "#### List all the files in each `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bad3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_paths = [glob.glob(pathname=path + '\\\\*') for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478901c0",
   "metadata": {},
   "source": [
    "#### Now we have all the file paths of the emails in the specified folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f4d8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0006.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0008.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0017.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0018.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0026.2003-12-18.GP.spam.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf0aa27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0001.1999-12-10.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0002.1999-12-13.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0003.1999-12-14.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0004.1999-12-14.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0005.1999-12-14.farmer.ham.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[1][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2590ad5",
   "metadata": {},
   "source": [
    "#### Having acquired the file paths, we can now extract the status, subject and message body of the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ec9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status has 16537 elements.\n",
      "Subject has 16537 elements.\n",
      "Body has 16537 elements.\n"
     ]
    }
   ],
   "source": [
    "subjects = []\n",
    "bodies = []\n",
    "status = []\n",
    "\n",
    "# for each path\n",
    "for file_path in file_paths:\n",
    "    # for each file in path\n",
    "    for i in file_path:\n",
    "        # for status\n",
    "        if 'spam.txt' in i:\n",
    "            status.append('spam')\n",
    "        elif 'ham.txt' in i:\n",
    "            status.append('ham')\n",
    "        # extract the subject from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            subject = f.readlines()[0]\n",
    "            subject = subject[9:]\n",
    "            subjects.append(subject)\n",
    "        # extract body message from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            body = f.readlines()\n",
    "            body = body[1:]\n",
    "            bodies.append(body)\n",
    "            \n",
    "# join each sub-elements of the bodies list\n",
    "bodies = [' '.join(i) for i in bodies]\n",
    "\n",
    "print('Status has', len(status), 'elements.')\n",
    "print('Subject has', len(subjects), 'elements.')\n",
    "print('Body has', len(bodies), 'elements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f0c4c",
   "metadata": {},
   "source": [
    "#### Now, use the lists to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351fdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6068cc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15501</th>\n",
       "      <td>ham</td>\n",
       "      <td>enron center south technology watch\\n</td>\n",
       "      <td>welcome to enron center south . as you have pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10469</th>\n",
       "      <td>ham</td>\n",
       "      <td>sevil yamin\\n</td>\n",
       "      <td>anne ,\\n vasant sent this information to norma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : corporate culture committee\\n</td>\n",
       "      <td>i love committees and this sounds like a real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : saudi arabia\\n</td>\n",
       "      <td>daren :\\n i ' ll follow - up on this , but i '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>ham</td>\n",
       "      <td>meter 7266\\n</td>\n",
       "      <td>daren - can you set up a deal for meter 7266 ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : meter 1517\\n</td>\n",
       "      <td>daren - after checking with mips , you are cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>ham</td>\n",
       "      <td>iris mack\\n</td>\n",
       "      <td>vince : i received a phone call yesterday afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13883</th>\n",
       "      <td>ham</td>\n",
       "      <td>rrevised weekly deal report\\n</td>\n",
       "      <td>please see the corrections to done deals ( int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15413</th>\n",
       "      <td>ham</td>\n",
       "      <td>fw : dynegy master netting / sithe\\n</td>\n",
       "      <td>carol st . clair\\n eb 4539\\n 713 - 853 - 3989 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12198</th>\n",
       "      <td>spam</td>\n",
       "      <td>please kindly respond ( dr . frank aluko )\\n</td>\n",
       "      <td>confidential\\n 2 adefobi street ,\\n ikoyi isla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Status                                       Subject  \\\n",
       "15501    ham         enron center south technology watch\\n   \n",
       "10469    ham                                 sevil yamin\\n   \n",
       "12820    ham            re : corporate culture committee\\n   \n",
       "2715     ham                           re : saudi arabia\\n   \n",
       "1741     ham                                  meter 7266\\n   \n",
       "3874     ham                             re : meter 1517\\n   \n",
       "9776     ham                                   iris mack\\n   \n",
       "13883    ham                 rrevised weekly deal report\\n   \n",
       "15413    ham          fw : dynegy master netting / sithe\\n   \n",
       "12198   spam  please kindly respond ( dr . frank aluko )\\n   \n",
       "\n",
       "                                                    Body  \n",
       "15501  welcome to enron center south . as you have pr...  \n",
       "10469  anne ,\\n vasant sent this information to norma...  \n",
       "12820  i love committees and this sounds like a real ...  \n",
       "2715   daren :\\n i ' ll follow - up on this , but i '...  \n",
       "1741   daren - can you set up a deal for meter 7266 ?...  \n",
       "3874   daren - after checking with mips , you are cor...  \n",
       "9776   vince : i received a phone call yesterday afte...  \n",
       "13883  please see the corrections to done deals ( int...  \n",
       "15413  carol st . clair\\n eb 4539\\n 713 - 853 - 3989 ...  \n",
       "12198  confidential\\n 2 adefobi street ,\\n ikoyi isla...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.DataFrame(list(zip(status,subjects,bodies)), columns=['Status','Subject','Body'])\n",
    "enron.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b51646",
   "metadata": {},
   "source": [
    "## 3. Build a Naive Bayes classifier to classify whether emails are spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416fc430",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ab5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5500efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7248</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : argentina power &amp; gas market modelling\\n</td>\n",
       "      <td>team ,\\n for me it \u0001 % s ok . let us know the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>ham</td>\n",
       "      <td>fw : sitara eol bridge problem today\\n</td>\n",
       "      <td>fyi &gt; &gt; &gt; we were also monitoring the eol to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>ham</td>\n",
       "      <td>power 2000\\n</td>\n",
       "      <td>power 2000 - may 8 - 11\\n ?\\n please note to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>ham</td>\n",
       "      <td>adios . . .\\n</td>\n",
       "      <td>as most of you have probably heard already , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>ham</td>\n",
       "      <td>cdnow order confirmation\\n</td>\n",
       "      <td>dear daren ,\\n thank you for shopping at cdnow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Status                                        Subject  \\\n",
       "7248    ham  re : argentina power & gas market modelling\\n   \n",
       "5058    ham         fw : sitara eol bridge problem today\\n   \n",
       "7460    ham                                   power 2000\\n   \n",
       "2526    ham                                  adios . . .\\n   \n",
       "1827    ham                     cdnow order confirmation\\n   \n",
       "\n",
       "                                                   Body  \n",
       "7248  team ,\\n for me it \u0001 % s ok . let us know the ...  \n",
       "5058  fyi > > > we were also monitoring the eol to s...  \n",
       "7460  power 2000 - may 8 - 11\\n ?\\n please note to h...  \n",
       "2526  as most of you have probably heard already , i...  \n",
       "1827  dear daren ,\\n thank you for shopping at cdnow...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b55035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16537, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3608742",
   "metadata": {},
   "source": [
    "#### Create `Spam` column from the `Status` column and delete `Status` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e3abeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron['Spam'] = [1 if i == 'spam' else 0 for i in enron['Status']]\n",
    "enron.drop('Status', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f07ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>never get a traffic ticket again ! - ia 55 m\\n</td>\n",
       "      <td>have you been caught by a red light camera yet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>el paso statement on california situation\\n</td>\n",
       "      <td>in case you haven ' t already seen this :\\n el...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>re : meter 9707\\n</td>\n",
       "      <td>daren ,\\n fyi .\\n bob\\n - - - - - - - - - - - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>urgent paypal security notification\\n</td>\n",
       "      <td>security center advisory !\\n we recently notic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13707</th>\n",
       "      <td>louise\\n</td>\n",
       "      <td>hope all is well . you can reach me by phone o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Subject  \\\n",
       "1006   never get a traffic ticket again ! - ia 55 m\\n   \n",
       "10070     el paso statement on california situation\\n   \n",
       "3493                                re : meter 9707\\n   \n",
       "5611            urgent paypal security notification\\n   \n",
       "13707                                        louise\\n   \n",
       "\n",
       "                                                    Body  Spam  \n",
       "1006   have you been caught by a red light camera yet...     1  \n",
       "10070  in case you haven ' t already seen this :\\n el...     0  \n",
       "3493   daren ,\\n fyi .\\n bob\\n - - - - - - - - - - - ...     0  \n",
       "5611   security center advisory !\\n we recently notic...     1  \n",
       "13707  hope all is well . you can reach me by phone o...     0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb53f4",
   "metadata": {},
   "source": [
    "#### Split data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ecb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bf1f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(enron[\"Body\"], enron[\"Spam\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a4a17",
   "metadata": {},
   "source": [
    "#### Import libraries for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88e0ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92209936",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_X = vectorizer.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304322c9",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f000ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(tfidf_train_X.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19436235",
   "metadata": {},
   "source": [
    "## 4. What is the longest ham email?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f5525",
   "metadata": {},
   "source": [
    "#### Create a dataframe containing all ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e05f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "hams = enron[enron['Spam'] == 0][['Body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e701a44",
   "metadata": {},
   "source": [
    "#### Create a column containing the lengths of each emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056169d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hams['Lengths'] = [len(i) for i in hams['Body']]\n",
    "hams.drop('Body',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec0f45",
   "metadata": {},
   "source": [
    "#### Get the index of the longest ham email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5adc69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths    15750\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "longest_ham = hams.idxmax()\n",
    "print(longest_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c5715",
   "metadata": {},
   "source": [
    "#### Print the longest ham email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf8ac1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15750    enron : a wake - up call\\n the wall street jou...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.iloc[longest_ham,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf6e0a",
   "metadata": {},
   "source": [
    "#### The longest ham email has `230120` characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f681e228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lengths    230120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hams.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad864fb",
   "metadata": {},
   "source": [
    "## 5. What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f5022af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217f281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4962, 80072)\n",
      "Accuracy: 92.52 percent\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_X = vectorizer.transform(test_X)\n",
    "print(tfidf_test_X.shape)\n",
    "scores = cross_val_score(classifier, tfidf_test_X.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e6cd6",
   "metadata": {},
   "source": [
    "**Model accuracy is `92.52%`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2683e8",
   "metadata": {},
   "source": [
    "## 6. Include the Subject in the analysis of the emails, does the accuracy/performance of the model increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f251e2b",
   "metadata": {},
   "source": [
    "#### Create a new column containing the concatenation of email `Subject` and `Body`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e894750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron['Total'] = [sub + bod for (sub, bod) in zip(enron.iloc[:,0],enron.iloc[:,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b3b6707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Spam</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dobmeos with hgh my energy level has gone up !...</td>\n",
       "      <td>introducing\\n doctor - formulated\\n hgh\\n huma...</td>\n",
       "      <td>1</td>\n",
       "      <td>dobmeos with hgh my energy level has gone up !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your prescription is ready . . oxwq s f e\\n</td>\n",
       "      <td>low cost prescription medications\\n soma , ult...</td>\n",
       "      <td>1</td>\n",
       "      <td>your prescription is ready . . oxwq s f e\\nlow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get that new car 8434\\n</td>\n",
       "      <td>people nowthe weather or climate in any partic...</td>\n",
       "      <td>1</td>\n",
       "      <td>get that new car 8434\\npeople nowthe weather o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>await your response\\n</td>\n",
       "      <td>dear partner ,\\n we are a team of government o...</td>\n",
       "      <td>1</td>\n",
       "      <td>await your response\\ndear partner ,\\n we are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coca cola , mbna america , nascar partner with...</td>\n",
       "      <td>stock\\n profile\\n about\\n company\\n investment...</td>\n",
       "      <td>1</td>\n",
       "      <td>coca cola , mbna america , nascar partner with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  dobmeos with hgh my energy level has gone up !...   \n",
       "1        your prescription is ready . . oxwq s f e\\n   \n",
       "2                            get that new car 8434\\n   \n",
       "3                              await your response\\n   \n",
       "4  coca cola , mbna america , nascar partner with...   \n",
       "\n",
       "                                                Body  Spam  \\\n",
       "0  introducing\\n doctor - formulated\\n hgh\\n huma...     1   \n",
       "1  low cost prescription medications\\n soma , ult...     1   \n",
       "2  people nowthe weather or climate in any partic...     1   \n",
       "3  dear partner ,\\n we are a team of government o...     1   \n",
       "4  stock\\n profile\\n about\\n company\\n investment...     1   \n",
       "\n",
       "                                               Total  \n",
       "0  dobmeos with hgh my energy level has gone up !...  \n",
       "1  your prescription is ready . . oxwq s f e\\nlow...  \n",
       "2  get that new car 8434\\npeople nowthe weather o...  \n",
       "3  await your response\\ndear partner ,\\n we are a...  \n",
       "4  coca cola , mbna america , nascar partner with...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be1ab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(enron[\"Total\"], enron[\"Spam\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c1411db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_X = vectorizer.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94143437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(tfidf_train_X.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d486108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4962, 81140)\n",
      "Accuracy: 93.31 percent\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_X = vectorizer.transform(test_X)\n",
    "print(tfidf_test_X.shape)\n",
    "scores = cross_val_score(classifier, tfidf_test_X.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c698d",
   "metadata": {},
   "source": [
    "**The accuracy improved by `0.79%`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
