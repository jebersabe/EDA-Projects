{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6e674e",
   "metadata": {},
   "source": [
    "## 1. How many Spam Emails are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "568c63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spam(path = \"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\", folders = ['enron1','enron2','enron3']):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    #path = Path(\"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\")\n",
    "    path = Path(path)\n",
    "    spam_count = 0\n",
    "    for folder in folders:\n",
    "        file_names = os.listdir(path / folder / 'spam')\n",
    "        for file_name in file_names:\n",
    "            if 'spam' in file_name:\n",
    "                spam_count += 1\n",
    "    print('There are', spam_count, 'spam emails in', folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8210f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4492 spam emails in ['enron1', 'enron2', 'enron3']\n"
     ]
    }
   ],
   "source": [
    "count_spam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaac7f",
   "metadata": {},
   "source": [
    "## 2. Structure the email data from the 2 directories into 1 dataframe with columns: Status, Subject, Body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e5c65",
   "metadata": {},
   "source": [
    "Specify the folders that will be included and the path leading to the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2b233e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['enron1','enron2']\n",
    "status = ['spam','ham']\n",
    "path1 = \"D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\{folder}\\\\{status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d70fc",
   "metadata": {},
   "source": [
    "Create the paths containing all the desired emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e5234fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enron1', 'spam'), ('enron1', 'ham'), ('enron2', 'spam'), ('enron2', 'ham')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "directories = list(product(folders, status))\n",
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fabc7d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\spam',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron2\\\\ham']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for i in directories:\n",
    "    paths.append(path1.format(folder=i[0],status=i[1]))\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce068ee",
   "metadata": {},
   "source": [
    "List all the files in each `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "17bad3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_paths = [glob.glob(pathname=path + '\\\\*') for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478901c0",
   "metadata": {},
   "source": [
    "Now we have all the file paths of the emails in the specified folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01f4d8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0006.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0008.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0017.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0018.2003-12-18.GP.spam.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\spam\\\\0026.2003-12-18.GP.spam.txt']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf0aa27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0001.1999-12-10.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0002.1999-12-13.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0003.1999-12-14.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0004.1999-12-14.farmer.ham.txt',\n",
       " 'D:\\\\Cadetship\\\\IntroDS\\\\HW2\\\\apper-eda\\\\Notebooks\\\\data\\\\enron-data\\\\enron1\\\\ham\\\\0005.1999-12-14.farmer.ham.txt']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths[1][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2590ad5",
   "metadata": {},
   "source": [
    "Having acquired the file paths, we can now extract the status, subject and message body of the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6ec9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status has 11026 elements.\n",
      "Subject has 11026 elements.\n",
      "Body has 11026 elements.\n"
     ]
    }
   ],
   "source": [
    "subjects = []\n",
    "bodies = []\n",
    "status = []\n",
    "\n",
    "# for each path\n",
    "for file_path in file_paths:\n",
    "    # for each file in path\n",
    "    for i in file_path:\n",
    "        # for status\n",
    "        if 'spam.txt' in i:\n",
    "            status.append('spam')\n",
    "        elif 'ham.txt' in i:\n",
    "            status.append('ham')\n",
    "        # extract the subject from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            subject = f.readlines()[0]\n",
    "            subject = subject[9:]\n",
    "            subjects.append(subject)\n",
    "        # extract body message from email\n",
    "        with open(i,'r',errors='ignore') as f:\n",
    "            body = f.readlines()\n",
    "            body = body[1:]\n",
    "            bodies.append(body)\n",
    "            \n",
    "# join each sub-elements of the bodies list\n",
    "bodies = [' '.join(i) for i in bodies]\n",
    "\n",
    "print('Status has', len(status), 'elements.')\n",
    "print('Subject has', len(subjects), 'elements.')\n",
    "print('Body has', len(bodies), 'elements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f0c4c",
   "metadata": {},
   "source": [
    "Now, use the lists to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "351fdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6068cc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>ham</td>\n",
       "      <td>resume - marcia curry\\n</td>\n",
       "      <td>job posting response , i have not talked to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>ham</td>\n",
       "      <td>wellhead adjustments - may , 2001\\n</td>\n",
       "      <td>daren ,\\n please see the attached spreadsheet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>spam</td>\n",
       "      <td>great idea for you byrdshot\\n</td>\n",
       "      <td>mortgage rates are about to rise\\n cash in now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : garp\\n</td>\n",
       "      <td>frank ,\\n i have reviewed materials from garp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>ham</td>\n",
       "      <td>new 22 cpm color copier information\\n</td>\n",
       "      <td>kevin ,\\n i am not sure by what date you requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>ham</td>\n",
       "      <td>you are now subscribed to the frbnyrmagl list\\n</td>\n",
       "      <td>mon , 18 sep 2000 18 : 42 : 47\\n your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>ham</td>\n",
       "      <td>mcmullen outage\\n</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>ham</td>\n",
       "      <td>re : equistar deal tickets\\n</td>\n",
       "      <td>what is going on about this deal ? can we get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>spam</td>\n",
       "      <td>low cost high rated insurance . why pay more ?\\n</td>\n",
       "      <td>save\\n up to 70 % on your life insurance !\\n g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>ham</td>\n",
       "      <td>promotion\\n</td>\n",
       "      <td>vince : just a short note to congratulate you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Status                                           Subject  \\\n",
       "2500    ham                           resume - marcia curry\\n   \n",
       "4730    ham               wellhead adjustments - may , 2001\\n   \n",
       "5244   spam                     great idea for you byrdshot\\n   \n",
       "9237    ham                                       re : garp\\n   \n",
       "6954    ham             new 22 cpm color copier information\\n   \n",
       "8517    ham   you are now subscribed to the frbnyrmagl list\\n   \n",
       "2476    ham                                 mcmullen outage\\n   \n",
       "2148    ham                      re : equistar deal tickets\\n   \n",
       "5274   spam  low cost high rated insurance . why pay more ?\\n   \n",
       "6770    ham                                       promotion\\n   \n",
       "\n",
       "                                                   Body  \n",
       "2500  job posting response , i have not talked to th...  \n",
       "4730  daren ,\\n please see the attached spreadsheet ...  \n",
       "5244  mortgage rates are about to rise\\n cash in now...  \n",
       "9237  frank ,\\n i have reviewed materials from garp ...  \n",
       "6954  kevin ,\\n i am not sure by what date you requi...  \n",
       "8517  mon , 18 sep 2000 18 : 42 : 47\\n your subscrip...  \n",
       "2476  - - - - - - - - - - - - - - - - - - - - - - fo...  \n",
       "2148  what is going on about this deal ? can we get ...  \n",
       "5274  save\\n up to 70 % on your life insurance !\\n g...  \n",
       "6770  vince : just a short note to congratulate you ...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.DataFrame(list(zip(status,subjects,bodies)), columns=['Status','Subject','Body'])\n",
    "enron.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b51646",
   "metadata": {},
   "source": [
    "## 3. Build a Naive Bayes classifier to classify whether emails are spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "37ab5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb53f4",
   "metadata": {},
   "source": [
    "Split data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63ecb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1bf1f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(enron[\"Body\"], enron[\"Status\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88e0ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92209936",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_x = vectorizer.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9241c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value={i[1]:i[0] for i in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee7c58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_indexed = []\n",
    "for row in tfidf_train_x:\n",
    "    fully_indexed.append({index_value[column]:value for (column,value) in zip(row.indices,row.data)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
